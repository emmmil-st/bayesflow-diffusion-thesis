{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddc44c68",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddc44c68",
        "outputId": "8380099a-f5c7-41fd-9c20-d714fe0febe8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import bayesflow as bf\n",
        "import pickle\n",
        "import EZ2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1851b83",
      "metadata": {
        "id": "d1851b83"
      },
      "outputs": [],
      "source": [
        "def prior():\n",
        "  params = {}\n",
        "\n",
        "  # Drift rates v toward left and right responses\n",
        "  params['vL'] = np.random.uniform(0.1, 6.0)\n",
        "  params['vR'] = np.random.uniform(0.1, 6.0)\n",
        "\n",
        "  # Boundary separation a\n",
        "  params['a'] = np.random.uniform(0.3, 4.0)\n",
        "\n",
        "  # Relative starting point z\n",
        "  params['z'] = np.random.uniform(0.1, 0.9)\n",
        "\n",
        "  # Non-decision times ter for left and right responses (in seconds)\n",
        "  params['terL'] = np.random.uniform(0.1, 1.0)\n",
        "  params['terR'] = np.random.uniform(0.1, 1.0)\n",
        "\n",
        "  return params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11f62187",
      "metadata": {
        "id": "11f62187"
      },
      "outputs": [],
      "source": [
        "def forward_model_ez(vL, vR, a, z, terL, terR):\n",
        "    z_abs = z * a # convert relative z to absolute z\n",
        "\n",
        "    mrtR = EZ2.cmrt(vR, z_abs, a, s=1) + terR\n",
        "    vrtR = EZ2.cvrt(vR, z_abs, a, s=1)\n",
        "    peR = EZ2.pe(vR, z_abs, a, s=1)\n",
        "\n",
        "    mrtL = EZ2.cmrt(vL, a - z_abs, a, s=1) + terL\n",
        "    vrtL = EZ2.cvrt(vL, a - z_abs, a, s=1)\n",
        "    peL = EZ2.pe(vL, a - z_abs, a, s=1)\n",
        "\n",
        "    return {\n",
        "        'mrtL': mrtL,\n",
        "        'vrtL': vrtL,\n",
        "        'peL':  peL,\n",
        "        'mrtR': mrtR,\n",
        "        'vrtR': vrtR,\n",
        "        'peR':  peR\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8761b02",
      "metadata": {
        "id": "b8761b02"
      },
      "outputs": [],
      "source": [
        "simulator = bf.make_simulator([prior, forward_model_ez])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74ba22cc",
      "metadata": {
        "id": "74ba22cc"
      },
      "outputs": [],
      "source": [
        "par_names = ['vL', 'vR', 'a', 'z', 'terL', 'terR']\n",
        "data_names = ['mrtL', 'vrtL', 'peL', 'mrtR', 'vrtR', 'peR']\n",
        "\n",
        "adapter = (\n",
        "    bf.adapters.Adapter()\n",
        "    .keep(par_names + data_names)\n",
        "    .to_array()\n",
        "    .convert_dtype(\"float64\", \"float32\")\n",
        "    .concatenate(par_names, into=\"inference_variables\")\n",
        "    .concatenate(data_names, into=\"summary_variables\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78990e5b",
      "metadata": {
        "id": "78990e5b"
      },
      "outputs": [],
      "source": [
        "from keras import Model, Input\n",
        "from keras.layers import Layer\n",
        "\n",
        "# Define a simple identity summary network:\n",
        "# Since the training data already consists of summary statistics,\n",
        "# we pass them via an identity network.\n",
        "class IdentitySummaryNet(Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "    def compute_metrics(self, inputs, stage=None):\n",
        "        return {\"outputs\": self(inputs)}\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "summary_net = IdentitySummaryNet()\n",
        "\n",
        "from bayesflow.networks import CouplingFlow\n",
        "from bayesflow.workflows import BasicWorkflow\n",
        "\n",
        "flow = CouplingFlow(\n",
        "    num_coupling_layers=6,\n",
        "    hidden_units=[128, 128],\n",
        "    coupling_type=\"spline\",\n",
        "    batch_norm=True,\n",
        "    dropout=0.05,\n",
        "    tail_bound=5.0\n",
        ")\n",
        "\n",
        "wf = BasicWorkflow(\n",
        "    simulator=simulator,\n",
        "    adapter=adapter,\n",
        "    summary_network=summary_net,\n",
        "    inference_network=flow,\n",
        "    inference_variables=[\"inference_variables\"],\n",
        "    summary_variables=[\"summary_variables\"],\n",
        "    standardize=[\"summary_variables\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39449225",
      "metadata": {
        "id": "39449225"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, BackupAndRestore\n",
        "\n",
        "es = EarlyStopping(\n",
        "    monitor=\"loss\",\n",
        "    min_delta=0.001,\n",
        "    patience=20,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    BackupAndRestore(backup_dir=\"./ez_backup\"),\n",
        "    ModelCheckpoint(\"ez_model_ckpt.keras\", monitor=\"loss\", save_best_only=True),\n",
        "    es\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b212efa2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b212efa2",
        "outputId": "1ed726ea-0efa-4f44-daa6-e5e4b0e0272f"
      },
      "outputs": [],
      "source": [
        "history = wf.fit_online(\n",
        "    epochs = 2000,\n",
        "    num_batches_per_epoch = 200,\n",
        "    batch_size = 64,\n",
        "    callbacks = [ckpt, es, csv_logger]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "094d090c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "094d090c",
        "outputId": "da258a7d-9238-4687-8c17-776bbde08af5"
      },
      "outputs": [],
      "source": [
        "f = bf.diagnostics.plots.loss(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NR2VaS4HzD8v",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "NR2VaS4HzD8v",
        "outputId": "5f7c0f35-d5ae-49df-8c7b-5329cea55a8e"
      },
      "outputs": [],
      "source": [
        "num_samples = 1000\n",
        "\n",
        "# Simulate validation data (unseen during training)\n",
        "val_sims = simulator.sample(200)\n",
        "\n",
        "# Obtain num_samples samples of the parameter posterior for every validation dataset\n",
        "post_draws = wf.sample(conditions=val_sims, num_samples=num_samples)\n",
        "\n",
        "f = bf.diagnostics.plots.recovery(\n",
        "    estimates=post_draws,\n",
        "    targets=val_sims,\n",
        "    variable_names=par_names\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a71D4QwRzF7d",
      "metadata": {
        "id": "a71D4QwRzF7d"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "out = Path.cwd() / \"standard_model.keras\"\n",
        "out.parent.mkdir(exist_ok=True, parents=True)\n",
        "wf.approximator.save(out)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
